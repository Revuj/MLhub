{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Image Classfication\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv1D, Conv2D, Conv3D, Dropout, MaxPooling1D, MaxPooling2D, MaxPooling3D, AveragePooling1D, AveragePooling2D, AveragePooling3D, BatchNormalization\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start stopwatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from time import process_time\n",
    "time_start = process_time() \n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.read_csv('/home/vitor/Documents/TACS/MLhub/data/cnn/features.csv')\n",
    "y = pd.read_csv('/home/vitor/Documents/TACS/MLhub/data/cnn/labels.csv')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.1,\n",
    "                        train_size=None,\n",
    "                        random_state=0,\n",
    "                        shuffle=0,\n",
    "                        stratify=X if \"None\" == \"features\" else y if \"None\" == \"labels\" else None)\n",
    "y_true = y_test\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_preprocessing(X, y):\n",
    "\n",
    "    out_y = keras.utils.to_categorical(y)\n",
    "\n",
    "    num_images = X.shape[0]\n",
    "    x_as_array = X.values[:,0:]\n",
    "    x_shaped_array = x_as_array.reshape(num_images, 28, 28, 1)\n",
    "    out_x = x_shaped_array / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "X_train, y_train = data_preprocessing(X_train, y_train)\n",
    "X_test, y_test = data_preprocessing(X_test, y_test)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=[3, 3], activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D([2, 2]))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=[3, 3], activation=\"relu\"))\n",
    "model.add(MaxPooling2D([2, 2]))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, kernel_size=[3, 3], activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(\n",
    "            loss=keras.losses.CategoricalCrossentropy(),\n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                  batch_size=128,\n",
    "                  epochs=2,\n",
    "                  validation_split=0.1)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Train Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "pred = model.predict(X_test) \n",
    "y_pred = np.argmax(pred, axis = 1) \n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')**0.5\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f'Accuracy Score: {acc}')\n",
    "print(f'Precision Score: {precision}')\n",
    "print(f'Recall Score: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_df = pd.DataFrame(cm)           \n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix');           \n",
    "plt.show()\n",
    "\n",
    "time_stop = process_time()\n",
    "cpu_time = round(time_stop - time_start, 2)\n",
    "print(f'Elapsed CPU Time: {cpu_time} seconds')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "path = 'statistics'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "stats = {\n",
    "    \"Accuracy Score\": acc,\n",
    "    \"Precision Score\": precision,\n",
    "    \"Recall Score\": recall,\n",
    "    \"F1 Score\": f1,\n",
    "    \"cpu time\": cpu_time,\n",
    "    \"predicted\": y_pred.flatten().tolist(), \n",
    "    \"real\": y_true.to_numpy().flatten().tolist()\n",
    "}\n",
    "\n",
    "with open(os.path.join(path, \"cnn_71103630-7d48-11ec-b088-d7c57270a0f7.json\"), \"w\") as f:\n",
    "    json.dump(stats, f, ensure_ascii=False, indent=4)\n",
    ""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767b48e45bc6c990438a60469f8fea24552342bcd924b4bf84434b657f97d9ac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}