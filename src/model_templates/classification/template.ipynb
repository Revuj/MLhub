{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "{% block title %}\n",
    "{% endblock %}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "{% block imports %}\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "{% endblock %}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start stopwatch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "{% block stopwatch %}\n",
    "from time import process_time\n",
    "time_start = process_time() \n",
    "{% endblock %}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "{% block dataset %}\n",
    "X = pd.read_csv('{{ features_file_path }}')\n",
    "y = pd.read_csv('{{ labels_file_path }}')\n",
    "{% endblock %}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Categorize dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def categorize_column(dataframe, category_threshold, column):\n",
    "    \n",
    "    uniq = dataframe[column].unique()\n",
    "    if len(uniq) <= category_threshold:\n",
    "        dataframe[column] = dataframe[column].astype('category').cat.codes\n",
    "        \n",
    "\n",
    "def categorize_dataframe(dataframe, category_threshold):\n",
    "    for c in dataframe.columns:\n",
    "        categorize_column(dataframe, category_threshold, c)\n",
    "        \n",
    "categorize_dataframe(X, {{ category_threshold }})\n",
    "categorize_dataframe(y, {{ category_threshold }})\n",
    "X = X.values\n",
    "y = y.values\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "{% block split %}\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size={{train_split.test_size}},\n",
    "                        train_size={{train_split.train_size}},\n",
    "                        random_state={{train_split.random_state}},\n",
    "                        shuffle={{train_split.random_state}},\n",
    "                        stratify=X if \"{{train_split.stratify}}\" == \"features\" else y if \"{{train_split.stratify}}\" == \"labels\" else None)\n",
    "{% endblock %}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Simple Decision Tree model on the Training set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "{% block train %}\n",
    "{% endblock %}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting the Test set results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "{% block predict %}\n",
    "y_pred = classifier.predict(X_test)\n",
    "{% endblock %}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating the Model Performance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "{% block evaluate %}\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)**0.5\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Accuracy Score: {acc}')\n",
    "print(f'Precision Score: {precision_score}')\n",
    "print(f'Recall Score: {recall_score}')\n",
    "print(f'F1 Score: {f1_score}')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm)           \n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix');           \n",
    "plt.show()\n",
    "\n",
    "time_stop = process_time()\n",
    "cpu_time = round(time_stop - time_start, 2)\n",
    "print(f'Elapsed CPU Time: {cpu_time} seconds')\n",
    "{% endblock %}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving Model Statistics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "{% block save %}\n",
    "import os\n",
    "import json\n",
    "\n",
    "path = 'statistics'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "stats = {\n",
    "    \"Accuracy Score\": acc,\n",
    "    \"Precision Score\": precision,\n",
    "    \"Recall Score\": recall,\n",
    "    \"F1 Score\": f1,\n",
    "    \"cpu time\": cpu_time,\n",
    "    \"predicted\": y_pred.flatten().tolist(), \n",
    "    \"real\": y_test.flatten().tolist()\n",
    "}\n",
    "\n",
    "with open(os.path.join(path, \"{{ model_name }}.json\"), \"w\") as f:\n",
    "    json.dump(stats, f, ensure_ascii=False, indent=4)\n",
    "{% endblock %}"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.8.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.9 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "ce6b9bb680dc74cb622ad82a172082906f8bce9278027f36f6e7940b0e35625a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}